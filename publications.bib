@misc{ruiz2024:novel,
  title = {A Novel Approach for Automatic Program Repair Using Round-Trip Translation with Large Language Models},
  author = {Ruiz, Fernando Vallecillos and Grishina, Anastasiia and Hort, Max and Moonen, Leon},
  year = {2024},
  month = jan,
  number = {arXiv:2401.07994},
  eprint = {2401.07994},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2401.07994},
  urldate = {2025-09-18},
  abstract = {Research shows that grammatical mistakes in a sentence can be corrected by translating it to another language and back using neural machine translation with language models. We investigate whether this correction capability of Large Language Models (LLMs) extends to Automatic Program Repair (APR). Current generative models for APR are pre-trained on source code and fine-tuned for repair. This paper proposes bypassing the fine-tuning step and using Round-Trip Translation (RTT): translation of code from one programming language to another programming or natural language, and back. We hypothesize that RTT with LLMs restores the most commonly seen patterns in code during pre-training, i.e., performs a regression toward the mean, which removes bugs as they are a form of noise w.r.t. the more frequent, natural, bug-free code in the training data. To test this hypothesis, we employ eight recent LLMs pre-trained on code, including the latest GPT versions, and four common program repair benchmarks in Java. We find that RTT with English as an intermediate language repaired 101 of 164 bugs with GPT-4 on the HumanEval-Java dataset. Moreover, 46 of these are unique bugs that are not repaired by other LLMs fine-tuned for APR. Our findings highlight the viability of round-trip translation with LLMs as a technique for automated program repair and its potential for research in software engineering. Keywords: automated program repair, large language model, machine translation},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Software Engineering},
  file = {/Users/fernando/Zotero/storage/6PQERITQ/Ruiz et al. - 2024 - A Novel Approach for Automatic Program Repair using Round-Trip Translation with Large Language Model.pdf;/Users/fernando/Zotero/storage/9KPDMU2Q/2401.html}
}

@misc{ruiz2025:art,
  title = {The Art of Repair: Optimizing Iterative Program Repair with Instruction-Tuned Models},
  shorttitle = {The Art of Repair},
  author = {Ruiz, Fernando Vallecillos and Hort, Max and Moonen, Leon},
  year = {2025},
  month = may,
  number = {arXiv:2505.02931},
  eprint = {2505.02931},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2505.02931},
  urldate = {2025-09-18},
  abstract = {Automatic program repair (APR) aims to reduce the manual efforts required to identify and fix errors in source code. Before the rise of LLM-based agents, a common strategy was to increase the number of generated patches, sometimes to the thousands, to achieve better repair results on benchmarks. More recently, self-iterative capabilities enabled LLMs to refine patches over multiple rounds guided by feedback. However, literature often focuses on many iterations and disregards different numbers of outputs. We investigate an APR pipeline that balances these two approaches, the generation of multiple outputs and multiple rounds of iteration, while imposing a limit of 10 total patches per bug. We apply three SOTA instruction-tuned LLMs - DeepSeekCoder-Instruct, Codellama-Instruct, Llama3.1-Instruct - to the APR task. We further fine-tune each model on an APR dataset with three sizes (1K, 30K, 65K) and two techniques (Full Fine-Tuning and LoRA), allowing us to assess their repair capabilities on two APR benchmarks: HumanEval-Java and Defects4J. Our results show that by using only a fraction ({$<$}1\%) of the fine-tuning dataset, we can achieve improvements of up to 78\% in the number of plausible patches generated, challenging prior studies that reported limited gains using Full Fine-Tuning. However, we find that exceeding certain thresholds leads to diminishing outcomes, likely due to overfitting. Moreover, we show that base models greatly benefit from creating patches in an iterative fashion rather than generating them all at once. In addition, the benefit of iterative strategies becomes more pronounced in complex benchmarks. Even fine-tuned models, while benefiting less from iterations, still gain advantages, particularly on complex benchmarks. The research underscores the need for balanced APR strategies that combine multi-output generation and iterative refinement.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Software Engineering},
  file = {/Users/fernando/Zotero/storage/BUJEUKR3/Ruiz et al. - 2025 - The Art of Repair Optimizing Iterative Program Repair with Instruction-Tuned Models.pdf;/Users/fernando/Zotero/storage/ERMT5DL7/2505.html}
}

@inproceedings{vallecillosruiz2024:agentdriven,
  title = {Agent-Driven Automatic Software Improvement},
  booktitle = {Proceedings of the 28th {{International Conference}} on {{Evaluation}} and {{Assessment}} in {{Software Engineering}}},
  author = {Vallecillos Ruiz, Fernando},
  year = {2024},
  month = jun,
  series = {{{EASE}} '24},
  pages = {470--475},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3661167.3661171},
  urldate = {2025-09-18},
  abstract = {With software maintenance accounting for 50\% of the cost of developing software, enhancing code quality and reliability has become more critical than ever. In response to this challenge, this doctoral research proposal aims to explore innovative solutions by focusing on the deployment of agents powered by Large Language Models (LLMs) to perform software maintenance tasks. The iterative nature of agents, which allows for continuous learning and adaptation, can help surpass common challenges in code generation. One distinct challenge is the last-mile problems, errors at the final stage of producing functionally and contextually relevant code. Furthermore, this project aims to surpass the inherent limitations of current LLMs in source code through a collaborative framework where agents can correct and learn from each other's errors. We aim to use the iterative feedback in these systems to further fine-tune the LLMs underlying the agents, becoming better aligned to the task of automated software improvement. Our main goal is to achieve a leap forward in the field of automatic software improvement by developing new tools and frameworks that can enhance the efficiency and reliability of software development.},
  isbn = {979-8-4007-1701-7},
  langid = {english},
  file = {/Users/fernando/Zotero/storage/T7Q2FTKJ/Vallecillos Ruiz - 2024 - Agent-driven automatic software improvement.pdf}
}
